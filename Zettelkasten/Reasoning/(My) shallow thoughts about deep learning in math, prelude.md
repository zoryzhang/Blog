[Source](https://siliconreckoner.substack.com/p/my-shallow-thoughts-about-deep-learning?utm_source=profile&utm_medium=reader2)

> _With attention-grabbing statements alleging AI superpowers, Big Tech leaders urge us to look to their version of the future, D&S Director of Research Jenna Burrell argues in a piece for Tech Policy Press. “[They are distracting us from the enormous amount of wealth and power they stand to gain from the rise of AI — and from the fact that it doesn’t have to be this way](https://datasociety.us7.list-manage.com/track/click?u=00b33d1beca407762446037f0&id=c8a9790beb&e=7069ebb24e),” she writes. “They would like to skip past today’s real work, that of tackling the challenges and wrestling with the possibilities that will shape the world to come. Instead, they ask us to look to the future — but they forget that the future belongs to us all.”_

> _“To focus on existential risk only, to drive the policymaking conversation in that direction, is a huge risk in and of itself,” D&S Executive Director Janet Haven tells Gabrielle Sierra, discussing AI on the Council on Foreign Relations’s Why It Matters podcast. “I’m concerned about the future of creativity. [I’m concerned about the future of things like care work and the lack of space that we have as a society to talk about what we're willing to automate and what we are not willing to automate](https://datasociety.us7.list-manage.com/track/click?u=00b33d1beca407762446037f0&id=abcd39495f&e=7069ebb24e)….So much of the decision-making in these systems and how they are designed, how they’re rolled out, who has access to them, is happening in a very tight circle of people and companies who have access to data, to compute, to money and to talent. And it is not a democratic process. It’s not a space for societal deliberation. That is very worrying to me.”_

If these questions are not too radical for the Council on Foreign Relations, surely the mathematical community can handle them. “Wealth and power,” “democratic process,” “decision-making”… was any of that on The Workshop’s agenda? Did any of the speakers talk about these issues? I’m looking forward to finding out.
...
**Hassett**, speaking as director of an Institute, whose role is to create communities of people, pointed out that collaboration styles, exemplified by the Lean community, are more complex than is traditional in the field.  To make progress in machine learning one needs the mathematicians who can formulate conjectures and see patterns, but also people who can get the software to work.  Institutions can help mathematicians find those collaborators.
...
_Mathematical scientists have to reflect on how we can provide enough flexibility in how we teach, so that these new things can seep into the curriculum at an early stage.  It doesn't need to be all AI or all formal things, but people can at least get some exposure in how they can use these as tools to generate understanding._
